---
title: "Lista 3 - Tópicos em ML"
execute:
  warning: false
author:   
  - Luben M. C. Cabezas
  - Reinaldo C. Anacleto
tbl-cap-location: top
format:
  pdf:
     df-print: kable
     include-in-header:  
        - text: |
            \usepackage{amsmath}
---
Primeiramente, importando bibliotecas que serão utilizadas:
```{r}
# bibliotecas do R
library(ggplot2)
library(MASS)
library(BART)
library(purrr)
library(dplyr)
library(FNN)
library(quantregForest)
```

\section{Exercício 1}
Importando o conjunto de dados de proteinas:
```{r}
# importando os dados
protein_data <- read.csv("data/CASP.csv")
# visualizando numero de variaveis, observações e tipo de cada variavel
protein_data |> str()
```
Dividindo o conjunto em treino, calibração e teste. O conjunto de calibração será usado apenas para os métodos conformal:
```{r}
set.seed(45)
# Dividindo em treino e teste
n_train_val <- floor(0.9 * nrow(protein_data))
train_val_ind <- sample(seq_len(nrow(protein_data)), n_train_val)
train_val_data <- protein_data[train_val_ind, ]
test_data <- protein_data[-train_val_ind, ]

# dividindo em treino e calibração
n_cal<- floor(0.5 * nrow(train_val_data))
train_cal_ind <- sample(seq_len(nrow(train_val_data)), n_cal)
calib_data <- train_val_data[train_cal_ind, ]
train_data <- train_val_data[-train_cal_ind, ]

# Transformando em matrizes
# matriz de features
X_train <- train_data |> dplyr::select(-1) |> as.matrix()
X_calib <- calib_data |> dplyr::select(-1) |> as.matrix()
X_test <- test_data |> dplyr::select(-1) |> as.matrix()

# features padronizados para o scale
# media e desvio padrao
mean_train <- colMeans(X_train)
sd_train <- sqrt(apply(X_train, 2, var))
X_train_scale <- X_train |> scale(center = mean_train, scale = sd_train)
X_calib_scale <- X_calib |> scale(center = mean_train, scale = sd_train)
X_test_scale <- X_test |> scale(center = mean_train, scale = sd_train)

# resposta
y_train <- train_data |> pull(1)
y_calib <- calib_data |> pull(1)
y_test <- test_data |> pull(1)

# matrizes para intervalos preditivos bayesiano
X_train_b <- train_val_data |> dplyr::select(-1) |> as.matrix()
y_train_b <- train_val_data |> pull(1)
n_test <- nrow(X_test)
```
\subsection{Item 1}

```{r}
# tunando o KNN num grid de K
# k_grid <- round(seq(1,50,length.out=10))

#erro <- rep(NA,length(k_grid))

#for (ii in seq_along(k_grid)) {
 # predito <- knn.reg(train=X_train_scale,
  #                 y=y_train,
   #                k=k_grid[ii])$pred
  #erro[ii] <- mean((predito-y_train)^2)
# }

best_k <- 10
#k_grid[which.min(erro)]

# predizendo para o conjunto de calibração
predito1 <- knn.reg(train=X_train_scale,
                  test=X_calib_scale,
                  y=y_train,
                  k=best_k)$pred

# predizendo para o conjunto de teste
predito2 <- knn.reg(train=X_train_scale,
                  test=X_test_scale,
                  y=y_train,
                  k=best_k)$pred

# calculando o conformal score
h_rs <- abs(predito1 - y_calib)

# estimando o corte
t1 <- quantile(h_rs, probs = 0.95)
cat("Corte estimado para o Regression Split: ", t1)
```

```{r}
# Estimando o corte para o weighted e rho
predito31 <- knn.reg(train=X_train_scale,
                   test=X_train_scale,
                   y=y_train,
                   k=best_k)$pred # E[Y|X](Treinamento)

# desvio absoluto para estimar o rho
y_ro <- abs(predito31 - y_train)
# estimando rho para o conjunto de calibracao
predito3 <- knn.reg(train=X_train_scale,
                  test=X_calib_scale,
                  y=y_ro,
                  k=best_k)$pred #\rho=E[Z|X]

# estimando quantil para o conjunto de calibracao
h_w <- (abs(predito1 - y_calib))/predito3
t2 <- quantile(h_w, probs = 0.95)

# estimando rho para o conjunto de teste
predito4 <- knn.reg(train=X_train_scale,
                  test=X_test_scale,
                  y=y_ro,
                  k=best_k)$pred #\rho=E[Z|X]
cat("Corte estimado para o Weighted: ", t2)
```

```{r}
#| cache: true
qrf_model <- quantregForest(
  x = X_train,  
  y = y_train,
  n_threads = 4,  
  ntree = 50,            
  nodesize = 10,
  sampsize = 30            
)

quantis <- c(0.05/2, 1 - (0.05/2))
pred_qrf <- predict(qrf_model, newdata =X_calib , what = quantis)

y_pred_05 <- pred_qrf[, 1]  # Quantil de 2.5%
y_pred_95 <- pred_qrf[, 2]  # Quantil de 97.5%

h_cqr <- pmax(y_pred_05 - y_calib, y_calib - y_pred_95)
t3<-quantile(h_cqr,probs = 0.95)

pred_qrf2 <- predict(qrf_model, newdata =X_test , what = quantis)
cat("Corte estimado para o CQR: ", t3)
```

```{r}
# obtendo limitest inferiores e superiores de cada metodo
# reg-split
lower_bound_rs <- predito2 - t1
upper_bound_rs <- predito2 + t1
# weighted
lower_bound_w <- predito2 - (t2*predito4)
upper_bound_w <- predito2 + (t2*predito4)
# CQR
lower_bound_cqr <- pred_qrf2[, 1] - t3
upper_bound_cqr <- pred_qrf2[, 2] + t3

# obtendo tamanho medio dos intervalos
data.frame(
  "Região Preditiva" = c("Reg-split", "Weighted", "CQR"),
  "Largura" = c(
    mean(upper_bound_rs- lower_bound_rs),
    mean(upper_bound_w - lower_bound_w),
    mean(upper_bound_cqr - lower_bound_cqr)),
  "SE*2" = c(
    2*sqrt(var(upper_bound_rs - lower_bound_rs)/n_test),
    2*sqrt(var(upper_bound_w - lower_bound_w)/n_test),
    2*sqrt(var(upper_bound_cqr - lower_bound_cqr)/n_test)
  )
)
```

\subsection{Item 2}
```{r}
sum(y_test>=predito2-t1 & y_test<=predito2+t1)/length(predito2)
```

```{r}
sum(y_test>=(predito2-predito4*t2) & y_test<=(predito2+predito4*t2))/length(predito2)
```

```{r}
sum(y_test>=(pred_qrf2[,1]-t3) & y_test<=(pred_qrf2[,2]+t3))/length(y_test)
```

\subsection{Item 3}
```{r}
#| label: fig-pred-int-conformal
#| fig-cap: "Intervalos preditivos conformais para as observações selecionadas. Pontos em vermelho representam o rótulo observado para cada observação."
#| fig-align: center
#| fig-pos: '!http'
#| echo: false
vals_idx <- c(2, 50, 175, 600, 1250)
true_y <- y_test[vals_idx]

pred_data <- data.frame(
  indices = c(paste0("Obs ", rep(vals_idx, 3))),
  lower_bound = c(
  lower_bound_rs[vals_idx], 
  lower_bound_w[vals_idx],
  lower_bound_cqr[vals_idx]),
  upper_bound = c(
    upper_bound_rs[vals_idx],
    upper_bound_w[vals_idx],
    upper_bound_cqr[vals_idx]
    ),
  truth_values = c(
    rep(true_y, 3)
  ),
  type = c(rep(c("Reg-split", "Weighted", "CQR"), each = 5)))

ggplot(pred_data, 
  aes(x = indices, ymin = lower_bound, 
  ymax = upper_bound, color = type)) +
  geom_linerange(position = position_dodge(width = 0.5), 
  size = 1) +  # Linhas de intervalo com deslocamento
  geom_point(aes(y = truth_values), 
  colour = "red", size = 2, 
  position = position_dodge(width = 0.5)) +  # Valores verdadeiros
  labs(
    title = "Comparação de Regiões Preditivas por Observação",
    x = "Observação",
    y = "Rótulo",
    color = "Método"
  ) +
  theme_minimal()
```
\subsection{Item 4}
Para esse exemplo, utilizaremos o conjunto de dados de treino completo. Utilizaremos o pacote BART no R, obtendo uma amostra de $1000$ da posteriori para obter as regiões preditivas para $Y$:
Agora ajustando o BART:
```{r}
#| cache: true
# Set seed for reproducibility
set.seed(686)
# Fit BART model
post <- wbart(X_train_b, y_train_b, X_test, ndpost = 1000)
```
Obtemos agora uma região preditiva simétrica e a região preditiva quantílica:
```{r}
alpha <- 0.05
# Obtendo os lower e upper bounds da regiao simetrica para o conjunto de teste
means <- post$yhat.test.mean
std_dev <- sqrt(mean(post$sigma)^2 + apply(post$yhat.test, 2, sd)^2)
lower_bound_sym <- means - 1.96 * std_dev
upper_bound_sym <- means + 1.96 * std_dev

sigmas <- post$sigma[101:1100]
# Obtendo os lower e upper bounds da região baseada nos quantis
# encontrando quantil inferior usando monte carlo
y_new <- 1:length(y_test) |>
map(function(.x){
  y_sim <- post$yhat.test[, .x]
  return(
    rnorm(length(y_sim), mean = y_sim, sd = sigmas)
  )
}) |> unlist() |> matrix(nrow = 1000)

# grid em y
lower_bound_q <- apply(y_new, 2, quantile, probs = alpha/2)
upper_bound_q <- apply(y_new, 2, quantile, probs = (1 - alpha/2)) 
```
Tendo ambas as regiões, podemos a seguir calcular a cobertura empírica nesses casos:
```{r}
cover_sym <- ((lower_bound_sym <= y_test) & 
(upper_bound_sym >= y_test)) |>
mean()

cover_q <- ((lower_bound_q <= y_test) & 
(upper_bound_q >= y_test)) |>
mean()

data.frame("Região Preditiva" = c("Simétrica", "Quantílica"),
"Cobertura empírica" = c(cover_sym, cover_q) |> round(4))
```
Percebe-se que ambas regiões são razoavelmente próximas da cobertura nominal 0.95, tendo porém uma leve sub-cobertura, principalmente a região quantílica que está um pouco mais distante do nível nominal que o intervalo simétrico. Podemos também observar pela [Figura @fig-pred-int-bayes] as regiões preditivas estimadas no conjunto de teste para 5 diferentes valores.
```{r}
#| label: fig-pred-int-bayes
#| fig-cap: "Intervalos preditivos bayesianos para as observações selecionadas. Pontos em vermelho representam o rótulo observado para cada observação enquanto pontos azuis representam a média a posteriori em cada caso."
#| fig-align: center
#| fig-pos: '!http'
#| echo: false

# valores para as regiões de predição
vals_idx <- c(2, 50, 175, 600, 1250)
true_y <- y_test[vals_idx]
pred_data <- data.frame(
  indices = c(paste0("Obs ", rep(vals_idx, 2))),
  lower_bound = c(
  lower_bound_sym[vals_idx], lower_bound_q[vals_idx]),
  upper_bound = c(upper_bound_sym[vals_idx],
  upper_bound_q[vals_idx]),
  truth_values = c(rep(true_y, 2)),
  mean_values = c(rep(means[vals_idx], 2)),
  type = c(rep(c("Simétrica", "Quantílica"), each = 5)))

# Plotting the pred_data lower and upper bound
ggplot(pred_data, 
  aes(x = indices, ymin = lower_bound, 
  ymax = upper_bound, color = type)) +
  geom_linerange(position = position_dodge(width = 0.5), 
  size = 1) +  # Linhas de intervalo com deslocamento
  geom_point(aes(y = truth_values), 
  colour = "red", size = 2, 
  position = position_dodge(width = 0.25)) +  # Valores verdadeiros 
  geom_point(aes(y = mean_values), 
  colour = "blue", size = 2, 
  position = position_dodge(width = 0.25)) +
  labs(
    title = "Comparação de Regiões Preditivas por Observação",
    x = "Observação",
    y = "Rótulo",
    color = "Método"
  ) +
  theme_minimal()
```
Primeiramente visualiza-se nesses casos em particular que todos os intervalos preditivos contém o valor observado de $Y$. Percebemos também que há poucas diferenças entre os tipos de regiões, com ambas tendo tamanhos similares e razoavelmente largos. Além disso, as regiões quantílicas são visualmente apenas um pouco assimétricas em torno da média e um pouco mais curtas que as regiões simétricas. Podemos comparar adicionalmente a largura média das regiões através da seguinte tabela:
```{r}
data.frame(
  "Região Preditiva" = c("Simétrica", "Quantílica"),
  "Largura" = c(
    mean(upper_bound_sym - lower_bound_sym),
    mean(upper_bound_q - lower_bound_q)),
  "SE*2" = c(
    2*sqrt(var(upper_bound_sym - lower_bound_sym)/n_test),
    2*sqrt(var(upper_bound_q - lower_bound_q)/n_test)
  )
)
```
Concluindo que de fato, as regiões quantílica são em média um pouco menos largas que as regiões simétricas.



